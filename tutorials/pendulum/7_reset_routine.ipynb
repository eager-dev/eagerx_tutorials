{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac5c1648-6268-4829-bbaf-53ef779bd1a0",
   "metadata": {},
   "source": [
    "# Tutorial 7: Reset Routines\n",
    "\n",
    "Resetting an object to a desired state is non-trivial in the real-world compared to simulation, where resets can often be caried out with a single command. In this tutorial, we will discuss methods to include reset routines into your graph that can reset an object's state that work both in simulation and the real-world. \n",
    "\n",
    "The following will be covered:\n",
    "<!-- - Defining an object's state with an [`EngineState`](https://eagerx.readthedocs.io/en/master/guide/api_reference/engine_state/index.html).  -->\n",
    "- Defining the reset routine with a [`ResetNode`](https://eagerx.readthedocs.io/en/master/guide/api_reference/node/reset_node.html).\n",
    "- Reset the object's state with the [`ResetNode`](https://eagerx.readthedocs.io/en/master/guide/api_reference/node/reset_node.html).\n",
    "\n",
    "In the remainder of this tutorial, we will go more into detail on this concept.\n",
    "\n",
    "Furthermore, at the end of this notebook you will find an exercise.\n",
    "For the exercise you will have to add/modify a couple of lines of code, which are marked by\n",
    "\n",
    "```python\n",
    "\n",
    "# START EXERCISE [BLOCK_NUMBER]\n",
    "\n",
    "# END EXERCISE [BLOCK_NUMBER]\n",
    "```\n",
    "\n",
    "## Pendulum Swing-up\n",
    "\n",
    "We will assume that we already have the object definition of the underactuated pendulum that we used in the [first](https://colab.research.google.com/github/eager-dev/eagerx_tutorials/blob/master/tutorials/pendulum/1_environment_creation.ipynb) tutorial with its dynamics simulated with the [OdeEngine](https://github.com/eager-dev/eagerx_ode). \n",
    "\n",
    "Our goal is to create a [`ResetNode`](https://eagerx.readthedocs.io/en/master/guide/api_reference/node/reset_node.html) that can reset the pendulum to a desired state (i.e. $\\theta=\\theta_\\text{des}$ and $\\dot{\\theta}=0$) without requiring a simulator reset. In other words, the [`ResetNode`](https://eagerx.readthedocs.io/en/master/guide/api_reference/node/reset_node.html) will receive the desired state as a target and it will send actuator commands until the pendulum has reached this state.\n",
    "\n",
    "## Activate GPU (Colab only)\n",
    "\n",
    "When in Colab, you'll need to enable GPUs for the notebook:\n",
    "\n",
    "- Navigate to Editâ†’Notebook Settings\n",
    "- select GPU from the Hardware Accelerator drop-down\n",
    "\n",
    "## Notebook Setup\n",
    "\n",
    "In order to be able to run the code, we need to install the *eagerx_tutorials* package and ROS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca8b6d03-40d4-4b45-92b2-61ffa09a3249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not running on CoLab.\n",
      "Execute ROS commands as \"!...\".\n",
      "ROS noetic available.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import eagerx_tutorials\n",
    "except ImportError:\n",
    "    !{\"echo 'Installing eagerx-tutorials with pip.' && pip install eagerx-tutorials  >> /tmp/eagerx_install.txt 2>&1\"}\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "  !{\"curl 'https://raw.githubusercontent.com/eager-dev/eagerx_tutorials/master/scripts/setup_colab.sh' > ~/setup_colab.sh\"}\n",
    "  !{\"bash ~/setup_colab.sh\"}\n",
    "\n",
    "# Setup interactive notebook\n",
    "# Required in interactive notebooks only.\n",
    "from eagerx_tutorials import helper\n",
    "helper.setup_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320d7676-c74e-4760-932e-4a347d7cfc5c",
   "metadata": {},
   "source": [
    "## Let's get started\n",
    "\n",
    "We start by importing the required packages and initializing EAGERx."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da87b514-cde8-4ff3-968b-718fe1b5c38c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... logging to /home/jelle/.ros/log/831de3ae-dc48-11ec-a29a-31e71ff4a2a0/roslaunch-jelle-Alienware-m15-R4-13788.log\n",
      "\u001b[1mstarted roslaunch server http://jelle-Alienware-m15-R4:35857/\u001b[0m\n",
      "ros_comm version 1.15.14\n",
      "\n",
      "\n",
      "SUMMARY\n",
      "========\n",
      "\n",
      "PARAMETERS\n",
      " * /rosdistro: noetic\n",
      " * /rosversion: 1.15.14\n",
      "\n",
      "NODES\n",
      "\n",
      "[INFO] [1653496648.625742]: Roscore cannot run as another roscore/master is already running. Continuing without re-initializing the roscore.\n"
     ]
    }
   ],
   "source": [
    "import eagerx\n",
    "import eagerx_tutorials.pendulum  # Registers Pendulum\n",
    "\n",
    "# Initialize eagerx (starts roscore if not already started.)\n",
    "eagerx.initialize(\"eagerx_core\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ff0b7a-16a8-4628-9fe0-0f16e3a3804a",
   "metadata": {},
   "source": [
    "## How do [ResetNodes](https://eagerx.readthedocs.io/en/master/guide/api_reference/node/reset_node.html) work?\n",
    "\n",
    "As mentioned before, resetting an object is non-trivial in the real-world compared to simulation, where resets can often be caried out with a single command. We developed [`ResetNodes`](https://eagerx.readthedocs.io/en/master/guide/api_reference/node/reset_node.html) in EAGERx to allow users to easily define reset routines that may, for example use pre-defined controllers, to reset an Object to a desired state.\n",
    "\n",
    "The structure of a [`ResetNode`](https://eagerx.readthedocs.io/en/master/guide/api_reference/node/reset_node.html) is very similar to a conventional [`Node`](https://eagerx.readthedocs.io/en/master/guide/api_reference/node/node.html). However, the [`callback()`](https://eagerx.readthedocs.io/en/master/guide/api_reference/node/reset_node.html#eagerx.core.entities.ResetNode.callback) of a [`ResetNode`](https://eagerx.readthedocs.io/en/master/guide/api_reference/node/reset_node.html) is skipped until the agent/user calls [`.reset()`](https://eagerx.readthedocs.io/en/master/guide/api_reference/env/index.html#eagerx.core.env.EagerxEnv.reset) on the gym evironment. At that moment, the desired state that that was selected in the [reset function](https://eagerx.readthedocs.io/en/master/guide/api_reference/env/index.html#eagerx.core.env.EagerxEnv.reset_fn) (convered in [this tutorial](https://colab.research.google.com/github/eager-dev/eagerx_tutorials/blob/master/tutorials/pendulum/2_reset_and_step.ipynb)) is send to the [`ResetNode`](https://eagerx.readthedocs.io/en/master/guide/api_reference/node/reset_node.html) as a `target` state.\n",
    "\n",
    "The [`ResetNode`](https://eagerx.readthedocs.io/en/master/guide/api_reference/node/reset_node.html) takes over control and starts sending commands to the object's actuators until the object's current state is equal (or close to) that target state. In other words, after the agent/user calls [`.reset()`](https://eagerx.readthedocs.io/en/master/guide/api_reference/env/index.html#eagerx.core.env.EagerxEnv.reset) the [`ResetNode.callback()`](https://eagerx.readthedocs.io/en/master/guide/api_reference/node/reset_node.html#eagerx.core.entities.ResetNode.callback) is called at the specified node `rate` with the connected `inputs` together with the `target` state and will produce `outputs` that bring the object's state closer to the desired state. During each callback, the [`ResetNode`](https://eagerx.readthedocs.io/en/master/guide/api_reference/node/reset_node.html) assess the status of the reset routine (i.e. whether the `target` state was reached) and communicates this status to the engine with a message.    \n",
    "\n",
    "**Important**: To assure input-output synchronization in [`sync`](https://eagerx.readthedocs.io/en/master/guide/api_reference/engine/index.html#eagerx.core.entities.Engine.sync) mode, the [`ResetNode`](https://eagerx.readthedocs.io/en/master/guide/api_reference/node/reset_node.html) must be placed in-between the actions commanded by the agent/user and the object actuator. Over the course of an episode, the reset node simply feeds through all commands, and only after [`.reset()`](https://eagerx.readthedocs.io/en/master/guide/api_reference/env/index.html#eagerx.core.env.EagerxEnv.reset) is called, will the commands be produced by [`ResetNode.callback()`](https://eagerx.readthedocs.io/en/master/guide/api_reference/node/reset_node.html#eagerx.core.entities.ResetNode.callback). The reset node's `rate` is constrained to be equal to the rate of the commands that it must feedthrough. \n",
    "## How to define a [ResetNode](https://eagerx.readthedocs.io/en/master/guide/api_reference/node/reset_node.html)?\n",
    "\n",
    "We can create a reset node by inheriting from the class [`ResetNode`](https://eagerx.readthedocs.io/en/master/guide/api_reference/node/reset_node.html).\n",
    "This class has the following abstract methods we need to implement:\n",
    "\n",
    "- [`spec()`](https://eagerx.readthedocs.io/en/master/guide/api_reference/node/reset_node.html#eagerx.core.entities.ResetNode.spec): Specifies the parameters of the node.\n",
    "- [`initialize()`](https://eagerx.readthedocs.io/en/master/guide/api_reference/node/reset_node.html#eagerx.core.entities.ResetNode.initialize): Initializes the node.\n",
    "- [`reset()`](https://eagerx.readthedocs.io/en/master/guide/api_reference/node/reset_node.html#eagerx.core.entities.ResetNode.reset): Resets the node at the beginning of an episode.\n",
    "- [`callback()`](https://eagerx.readthedocs.io/en/master/guide/api_reference/node/reset_node.html#eagerx.core.entities.ResetNode.callback): Called at the rate of the node after the agent/user calls [`.reset()`](https://eagerx.readthedocs.io/en/master/guide/api_reference/env/index.html#eagerx.core.env.EagerxEnv.reset) on the gym evironment. It receives all connected `inputs` and `targets` as arguments.\n",
    "\n",
    "\n",
    "## An example [ResetNode](https://eagerx.readthedocs.io/en/master/guide/api_reference/node/reset_node.html)\n",
    "\n",
    "To illustrate how [`ResetNodes`](https://eagerx.readthedocs.io/en/master/guide/api_reference/node/reset_node.html) work, we will again create an environment with the *Pendulum* object, like we did in the [first](https://colab.research.google.com/github/eager-dev/eagerx_tutorials/blob/master/tutorials/pendulum/1_environment_creation.ipynb) and [second](https://colab.research.google.com/github/eager-dev/eagerx_tutorials/blob/master/tutorials/pendulum/2_reset_and_step.ipynb) tutorials. We will add a [`ResetNode`](https://eagerx.readthedocs.io/en/master/guide/api_reference/node/reset_node.html) called `angle_reset` and connect it as illustrated in the graph below:\n",
    "\n",
    "<img src=\"./figures/tutorial_7_gui.svg\" width=720>\n",
    "\n",
    "- We connect the actions commanded by the agent (i.e. `voltage`) to the `feedthrough` connection `u` (light blue color) and we connect the `angle_reset`'s output `u` to the pendulum's actuator `u`. In this way, the `voltage` actions will be fed through to the output `u` during an episode, while the `angle_reset`'s [`callback()`](https://eagerx.readthedocs.io/en/master/guide/api_reference/node/reset_node.html#eagerx.core.entities.ResetNode.callback) will produce the outputs during a reset.\n",
    "- We connect the pendulum's `model_state` to the `angle_reset`'s target `goal`. In this way, the `angle_reset`'s [`callback()`](https://eagerx.readthedocs.io/en/master/guide/api_reference/node/reset_node.html#eagerx.core.entities.ResetNode.callback) will receive the desired `model_state` as an argument.\n",
    "- To assess the status of the reset routine (i.e. whether the `model_state` state was reached, we connect the two pendulum sensors `theta` and `dtheta` as inputs to `angle_reset`.\n",
    "\n",
    "Below, the definition of this reset node is given. Currently, the node uses a [PID](https://en.wikipedia.org/wiki/PID_controller) to reset the pendulum to a angle with zero angular velocity. If the reset takes too long, we timeout and consider the reset finished regardless of whether the target state was reached.\n",
    "\n",
    "In the exercise of this tutorial, we will modify this routine to, instead, apply random actions for a fixed amount of time (disregarding the desired state)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "878e4395-cb31-40ed-9974-b4b82ae0c644",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, List\n",
    "import eagerx\n",
    "from eagerx.utils.utils import Msg\n",
    "from std_msgs.msg import Float32MultiArray, Float32, Bool\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def wrap_angle(angle):\n",
    "    return angle - 2 * np.pi * np.floor((angle + np.pi) / (2 * np.pi))\n",
    "\n",
    "\n",
    "class ResetAngle(eagerx.ResetNode):\n",
    "    @staticmethod\n",
    "    @eagerx.register.spec(\"ResetAngle\", eagerx.ResetNode)\n",
    "    def spec(\n",
    "        spec,\n",
    "        name: str,\n",
    "        rate: float,\n",
    "        threshold: float = 0.1,\n",
    "        timeout: float = 5.0,\n",
    "        gains: Optional[List[float]] = None,\n",
    "        u_range: Optional[List[float]] = None,\n",
    "    ):\n",
    "        \"\"\"This AngleReset node resets the pendulum to a desired angle with zero angular velocity. Note that this controller\n",
    "        only works properly when resetting the pendulum near the downward facing equilibrium.\n",
    "\n",
    "        :param spec: Not provided by the user. Contains the configuration of this node to initialize it at run-time.\n",
    "        :param name: Node name\n",
    "        :param rate: Rate at which callback is called. Must be equal to the rate of the nodes that are connect to the feedthroughs.\n",
    "        :param threshold: Absolute difference between the desired and goal state before considering the reset complete.\n",
    "        :param timeout: Maximum time (seconds) before considering the reset finished (regardless whether the goal was reached).\n",
    "        :param gains: Gains of the PID controller used to reset.\n",
    "        :param u_range: Min and max action.\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        # Performs all the steps to fill-in the params with registered info about all functions.\n",
    "        # Note: not to be confused with the initialize method of this node.\n",
    "        spec.initialize(ResetAngle)\n",
    "\n",
    "        # Modify default node params\n",
    "        spec.config.update(name=name, rate=rate, process=eagerx.process.ENVIRONMENT, color=\"grey\")\n",
    "        spec.config.update(inputs=[\"theta\", \"dtheta\"], targets=[\"goal\"], outputs=[\"u\"])\n",
    "        spec.config.update(u_range=u_range, threshold=threshold, timeout=timeout)\n",
    "        # Proportional (Kp), derivative (Kd) and integral (Ki) gains\n",
    "        spec.config.gains = gains if isinstance(gains, list) else [1.0, 0.5, 0.0]\n",
    "\n",
    "        # Add space_converter\n",
    "        c = eagerx.SpaceConverter.make(\"Space_Float32MultiArray\", [u_range[0]], [u_range[1]], dtype=\"float32\")\n",
    "        spec.outputs.u.space_converter = c\n",
    "\n",
    "    def initialize(self, threshold: float, timeout: float, gains: List[float], u_range: List[float]):\n",
    "        self.threshold = threshold\n",
    "        self.timeout = timeout\n",
    "        self.u_min, self.u_max = u_range\n",
    "\n",
    "        # Creat a simple PID controller\n",
    "        from eagerx_tutorials.pendulum.pid import PID\n",
    "        self.controller = PID(u0=0.0, kp=gains[0], kd=gains[1], ki=gains[2], dt=1 / self.rate)\n",
    "\n",
    "    @eagerx.register.states()\n",
    "    def reset(self):\n",
    "        # Reset the internal state of the PID controller (ie the error term).\n",
    "        self.controller.reset()\n",
    "        self.ts_start_routine = None\n",
    "\n",
    "    @eagerx.register.inputs(theta=Float32, dtheta=Float32)\n",
    "    @eagerx.register.targets(goal=Float32MultiArray)\n",
    "    @eagerx.register.outputs(u=Float32MultiArray)\n",
    "    def callback(self, t_n: float, goal: Msg, theta: Msg, dtheta: Msg):\n",
    "        if self.ts_start_routine is None:\n",
    "            self.ts_start_routine = t_n\n",
    "\n",
    "        # Convert messages to floats and numpy array\n",
    "        theta = theta.msgs[-1].data  # Take the last received message\n",
    "        dtheta = dtheta.msgs[-1].data  # Take the last received message\n",
    "        goal = np.array(goal.msgs[-1].data, dtype=\"float32\")  # Take the last received message\n",
    "\n",
    "        # Define downward angle as theta=0 (resolve downward discontinuity)\n",
    "        theta += np.pi\n",
    "        goal[0] += np.pi\n",
    "\n",
    "        # Wrap angle between [-pi, pi]\n",
    "        theta = wrap_angle(theta)\n",
    "        goal[0] = wrap_angle(goal[0])\n",
    "\n",
    "        # Overwrite the desired velocity to be zero.\n",
    "        goal[1] = 0.0\n",
    "\n",
    "        # Calculate the action using the PID controller\n",
    "        # START EXERCISE 1.2\n",
    "        # Select random actions instead.\n",
    "        u = self.controller.next_action(theta, ref=goal[0])\n",
    "        u = np.clip(u, self.u_min, self.u_max)  # Clip u to range\n",
    "        \n",
    "\n",
    "        # Determine if we have reached our goal state\n",
    "        done = np.isclose(np.array([theta, dtheta]), goal, atol=self.threshold).all()\n",
    "        \n",
    "        # If the reset routine takes too long, we timeout the routine and simply assume that we are done.\n",
    "        done = done or (t_n - self.ts_start_routine) > self.timeout\n",
    "        # END EXERCISE 1.2\n",
    "        \n",
    "        # Prepare output message for transmission.\n",
    "        # This must contain a message for every registered & selected output and target.\n",
    "        # For targets, this message decides whether the goal state has been reached (or we, for example, timeout the reset).\n",
    "        # The name for this target message is the registered target name + \"/done\".\n",
    "        output_msgs = {\"u\": Float32MultiArray(data=[u]), \"goal/done\": Bool(data=done)}\n",
    "        return output_msgs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e352c4-b765-4f3b-b870-358abe3b3916",
   "metadata": {},
   "source": [
    "After defining & registering the reset node above, we can create it and add it to the graph. We will then proceed to connect it according to the GUI visualization of the intended graph shown above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "858c3f13-6c63-4f92-88d3-872220769fae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define rate in Hz\n",
    "rate = 30.0\n",
    "\n",
    "# Initialize empty graph\n",
    "graph = eagerx.Graph.create()\n",
    "\n",
    "# Create a pendulum\n",
    "pendulum = eagerx.Object.make(\"Pendulum\", \"pendulum\", actuators=[\"u\"], sensors=[\"theta\", \"dtheta\", \"image\"], states=[\"model_state\"])\n",
    "\n",
    "# Add pendulum to the graph\n",
    "graph.add(pendulum)\n",
    "\n",
    "# Connect the pendulum to an action and observation\n",
    "graph.connect(source=pendulum.sensors.theta, observation=\"angle\")\n",
    "graph.connect(source=pendulum.sensors.dtheta, observation=\"angular_velocity\")\n",
    "\n",
    "# Create the reset node\n",
    "u_min = pendulum.actuators.u.space_converter.low[0]\n",
    "u_max = pendulum.actuators.u.space_converter.high[0]\n",
    "reset = eagerx.ResetNode.make(\"ResetAngle\", \"reset_angle\", rate, gains=[2.0, 0.2, 1.0], u_range=[u_min, u_max])\n",
    "\n",
    "# Add the reset node to the graph\n",
    "graph.add(reset)\n",
    "\n",
    "# Connect the pendulum state as the reset's target.\n",
    "graph.connect(source=pendulum.states.model_state, target=reset.targets.goal)\n",
    "\n",
    "# Connect the action we are feeding through during the course of an episode, but will be produced by the reset node during a reset.\n",
    "# During normal operations, the ResetNode simply feeds through the voltage actionto reset.outputs.u.\n",
    "graph.connect(action=\"voltage\", target=reset.feedthroughs.u)\n",
    "\n",
    "# When env.reset() is called, no voltage actions are being send by the agent, because we are resetting.\n",
    "# At that moment, the ResetNode's callback will be called instead to produce the voltages. \n",
    "graph.connect(source=reset.outputs.u, target=pendulum.actuators.u)\n",
    "\n",
    "# To decide on the voltage actions that will bring the current pendulum state closer to the desired target state,\n",
    "# The ResetNode requires knowledge of the current pendulum angle information. Hence, we connect them as inputs.\n",
    "# These inputs are also used by the reset node to determine whether the target state has been reached.\n",
    "# If so, the reset node signals EagerxEnv that the desired state was reached.\n",
    "graph.connect(source=pendulum.sensors.theta, target=reset.inputs.theta)\n",
    "graph.connect(source=pendulum.sensors.dtheta, target=reset.inputs.dtheta)\n",
    "\n",
    "# Define the render source\n",
    "graph.render(source=pendulum.sensors.image, rate=rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78a4dd8-9a01-47fc-bbf8-b24a6e716a8e",
   "metadata": {},
   "source": [
    "Next, we will define a reset function for the environment that selects desired states. Unfortunately, we cannot sample any angle because the PID controller won't be able to reset to angles near the upright position due to the underactuation. Hence, we will start by always selecting the downward position of the pendulum. \n",
    "\n",
    "In the exercise, we will selecte angles that are sampled around the downward position of the pendulum to improve state-space coverage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "912cfd51-e9a6-48ff-82f0-dbee89123bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class PendulumEnv(eagerx.BaseEnv):\n",
    "    def __init__(self, name: str, rate: float, graph: eagerx.Graph, engine: eagerx.Engine):\n",
    "        \"\"\"Initializes an environment with EAGERx dynamics.\n",
    "\n",
    "        :param name: The name of the environment. Everything related to this environment\n",
    "                     (parameters, topics, nodes, etc...) will be registered under namespace: \"/[name]\".\n",
    "        :param rate: The rate (Hz) at which the environment will run.\n",
    "        :param graph: The graph consisting of nodes and objects that describe the environment's dynamics.\n",
    "        :param engine: The physics engine that will govern the environment's dynamics.\n",
    "        \"\"\"\n",
    "        self.eval = eval\n",
    "        \n",
    "        # Maximum episode length\n",
    "        self.max_steps = 100\n",
    "        \n",
    "        # Step counter\n",
    "        self.steps = None\n",
    "        super().__init__(name, rate, graph, engine, force_start=True)\n",
    "    \n",
    "    def step(self, action: Dict):\n",
    "        \"\"\"A method that runs one timestep of the environment's dynamics.\n",
    "\n",
    "        :params action: A dictionary of actions provided by the agent.\n",
    "        :returns: A tuple (observation, reward, done, info).\n",
    "\n",
    "            - observation: Dictionary of observations of the current timestep.\n",
    "\n",
    "            - reward: amount of reward returned after previous action\n",
    "\n",
    "            - done: whether the episode has ended, in which case further step() calls will return undefined results\n",
    "\n",
    "            - info: contains auxiliary diagnostic information (helpful for debugging, and sometimes learning)\n",
    "        \"\"\"\n",
    "        # Take step\n",
    "        observation = self._step(action)\n",
    "        self.steps += 1\n",
    "        \n",
    "        # Get angle and angular velocity\n",
    "        # Take first element because of window size (covered in other tutorial)\n",
    "        th = observation[\"angle\"][0]\n",
    "        thdot = observation[\"angular_velocity\"][0]\n",
    "\n",
    "        # Convert from numpy array to float\n",
    "        u = float(action[\"voltage\"])\n",
    "\n",
    "        # Calculate cost\n",
    "        # Penalize angle error, angular velocity and input voltage\n",
    "        cost = th**2 + 0.1 * thdot**2 + 0.001 * u**2  \n",
    "\n",
    "        # Determine when is the episode over\n",
    "        # currently just a timeout after 100 steps\n",
    "        done = self.steps > self.max_steps\n",
    "\n",
    "        # Set info, tell the algorithm the termination was due to a timeout\n",
    "        # (the episode was truncated)\n",
    "        info = {\"TimeLimit.truncated\": self.steps > self.max_steps}\n",
    "        \n",
    "        return observation, -cost, done, info\n",
    "    \n",
    "    def reset(self) -> Dict:\n",
    "        \"\"\"Resets the environment to an initial state and returns an initial observation.\n",
    "\n",
    "        :returns: The initial observation.\n",
    "        \"\"\"\n",
    "        # Determine reset states\n",
    "        states = self.state_space.sample()\n",
    "        \n",
    "        # START EXERCISE 1.1\n",
    "        # Sample angles near the downward position.\n",
    "        # Hint: angles are in [-pi, pi] and upright is theta=0.\n",
    "        states[\"pendulum/model_state\"] = np.array([np.pi, 0], dtype=\"float32\")\n",
    "        # END EXERCISE 1.1\n",
    "\n",
    "        # Perform reset\n",
    "        observation = self._reset(states)\n",
    "\n",
    "        # Reset step counter\n",
    "        self.steps = 0\n",
    "        return observation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405eb3cb-6675-429d-aa9f-77ffa21684c0",
   "metadata": {},
   "source": [
    "We will proceed with defining the engine and initializing the environment. \n",
    "\n",
    "Finally, we train the agent using [Stable Baselines3](https://stable-baselines3.readthedocs.io/en/master/), again similar to the preceding tutorials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d9d2bf3-8a66-4605-a31f-e785e0a17b0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [1653496648.853562]: Node \"/PendulumEnv/env/supervisor\" initialized.\n",
      "[INFO] [1653496649.048831]: Node \"/PendulumEnv/engine\" initialized.\n",
      "[INFO] [1653496649.247348]: Node \"/PendulumEnv/environment\" initialized.\n",
      "[INFO] [1653496649.323458]: Node \"/PendulumEnv/reset_angle\" initialized.\n",
      "[INFO] [1653496649.384690]: Node \"/PendulumEnv/pendulum/theta\" initialized.\n",
      "[INFO] [1653496649.394367]: Waiting for nodes \"['env/render']\" to be initialized.\n",
      "[INFO] [1653496649.413090]: Node \"/PendulumEnv/pendulum/dtheta\" initialized.\n",
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "[INFO] [1653496649.508353]: Adding object \"pendulum\" of type \"Pendulum\" to the simulator.\n",
      "[INFO] [1653496649.530587]: Node \"/PendulumEnv/pendulum/x\" initialized.\n",
      "[INFO] [1653496649.549228]: [pendulum/image] START RENDERING!\n",
      "[INFO] [1653496649.549464]: Node \"/PendulumEnv/pendulum/image\" initialized.\n",
      "[INFO] [1653496649.563660]: Node \"/PendulumEnv/pendulum/u\" initialized.\n",
      "[INFO] [1653496649.576958]: Node \"/PendulumEnv/pendulum/u_applied\" initialized.\n",
      "[INFO] [1653496654.102126]: Nodes initialized.\n",
      "[INFO] [1653496654.201948]: Pipelines initialized.\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 101       |\n",
      "|    ep_rew_mean     | -1.02e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 4         |\n",
      "|    fps             | 69        |\n",
      "|    time_elapsed    | 5         |\n",
      "|    total_timesteps | 404       |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 19.3      |\n",
      "|    critic_loss     | 0.764     |\n",
      "|    ent_coef        | 0.915     |\n",
      "|    ent_coef_loss   | -0.134    |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 303       |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 101      |\n",
      "|    ep_rew_mean     | -996     |\n",
      "| time/              |          |\n",
      "|    episodes        | 8        |\n",
      "|    fps             | 66       |\n",
      "|    time_elapsed    | 12       |\n",
      "|    total_timesteps | 808      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 34.7     |\n",
      "|    critic_loss     | 0.241    |\n",
      "|    ent_coef        | 0.816    |\n",
      "|    ent_coef_loss   | -0.295   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 707      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 101      |\n",
      "|    ep_rew_mean     | -968     |\n",
      "| time/              |          |\n",
      "|    episodes        | 12       |\n",
      "|    fps             | 65       |\n",
      "|    time_elapsed    | 18       |\n",
      "|    total_timesteps | 1212     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 50.2     |\n",
      "|    critic_loss     | 0.152    |\n",
      "|    ent_coef        | 0.73     |\n",
      "|    ent_coef_loss   | -0.37    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 1111     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 101      |\n",
      "|    ep_rew_mean     | -941     |\n",
      "| time/              |          |\n",
      "|    episodes        | 16       |\n",
      "|    fps             | 65       |\n",
      "|    time_elapsed    | 24       |\n",
      "|    total_timesteps | 1616     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 65.2     |\n",
      "|    critic_loss     | 0.0989   |\n",
      "|    ent_coef        | 0.664    |\n",
      "|    ent_coef_loss   | -0.403   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 1515     |\n",
      "---------------------------------\n",
      "[INFO] [1653496681.470113]: [PendulumEnv] Send termination signal to '/PendulumEnv/env/render'.\n",
      "[INFO] [1653496681.470924]: [PendulumEnv][/PendulumEnv/engine] Shutting down.\n",
      "[INFO] [1653496681.471595]: [/PendulumEnv/engine] Shutting down '/PendulumEnv/pendulum/x'.\n",
      "[INFO] [1653496681.472471]: [/PendulumEnv/pendulum/x] Shutting down.\n",
      "[INFO] [1653496681.528621]: [/PendulumEnv/engine] Shutting down '/PendulumEnv/pendulum/image'.\n",
      "[INFO] [1653496681.529445]: [/PendulumEnv/pendulum/image] Shutting down.\n",
      "[INFO] [1653496681.530235]: [/PendulumEnv/engine] Shutting down '/PendulumEnv/pendulum/u'.\n",
      "[INFO] [1653496681.530862]: [/PendulumEnv/pendulum/u] Shutting down.\n",
      "[INFO] [1653496681.531507]: [/PendulumEnv/engine] Shutting down '/PendulumEnv/pendulum/u_applied'.\n",
      "[INFO] [1653496681.532241]: [/PendulumEnv/pendulum/u_applied] Shutting down.\n",
      "[INFO] [1653496681.533047]: [/PendulumEnv/engine] Shutting down.\n",
      "[INFO] [1653496681.534451]: [PendulumEnv][/PendulumEnv/reset_angle] Shutting down.\n",
      "[INFO] [1653496681.535053]: [/PendulumEnv/reset_angle] Shutting down.\n",
      "[INFO] [1653496681.535789]: [PendulumEnv][/PendulumEnv/pendulum/theta] Shutting down.\n",
      "[INFO] [1653496681.536380]: [/PendulumEnv/pendulum/theta] Shutting down.\n",
      "[INFO] [1653496681.538499]: [PendulumEnv][/PendulumEnv/pendulum/dtheta] Shutting down.\n",
      "[INFO] [1653496681.539975]: [/PendulumEnv/pendulum/dtheta] Shutting down.\n",
      "[INFO] [1653496681.541128]: [/PendulumEnv/env/supervisor] Shutting down.\n",
      "[INFO] [1653496681.546870]: [/PendulumEnv/environment] Shutting down.\n",
      "[INFO] [1653496681.550127]: Parameters under namespace \"/PendulumEnv\" deleted.\n"
     ]
    }
   ],
   "source": [
    "import stable_baselines3 as sb3\n",
    "from eagerx.wrappers import Flatten\n",
    "\n",
    "\n",
    "# Make the engine\n",
    "import eagerx_ode  # Registers OdeEngine\n",
    "engine = eagerx.Engine.make(\"OdeEngine\", rate=rate)\n",
    "\n",
    "# Initialize Environment\n",
    "env = PendulumEnv(name=\"PendulumEnv\", rate=rate, graph=graph, engine=engine)\n",
    "\n",
    "# Toggle render\n",
    "env.render(\"human\")\n",
    "\n",
    "# Stable Baselines3 expects flattened actions & observations\n",
    "# Convert observation and action space from Dict() to Box()\n",
    "env = Flatten(env)\n",
    "\n",
    "# Initialize learner\n",
    "model = sb3.SAC(\"MlpPolicy\", env, verbose=1)\n",
    "\n",
    "# Train for 1 minute (sim time)\n",
    "model.learn(total_timesteps=int(60 * rate))\n",
    "\n",
    "env.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872df1d1-bed3-4b09-80dd-44c8b71a502d",
   "metadata": {},
   "source": [
    "# Exercise\n",
    "\n",
    "In this exercise you will modify the reset routine defined above. \n",
    "\n",
    "For this exercise, you will need to modify or add some lines of code in the cells above.\n",
    "These lines are indicated by the following comments:\n",
    "\n",
    "```python\n",
    "# START EXERCISE [BLOCK_NUMBER]\n",
    "\n",
    "# END EXERCISE [BLOCK_NUMBER]\n",
    "```\n",
    "\n",
    "However, feel free to play with the other code as well if you are interested.\n",
    "We recommend you to restart and run all code after each section (in Colab there is the option *Restart and run all* under *Runtime*).\n",
    "\n",
    "## 1. Modify the reset procedure\n",
    "\n",
    "\n",
    "### Add your code to the following blocks: \n",
    "\n",
    "1.1 Change the `reset()` method of the environment, such that the desired angles are sampled randomly around the downward position of the pendulum.\n",
    "This will improve state-space coverage and improve the learning rate.  \n",
    "1.2 Next, modify the callback of the reset node such that we do not use the PID controller, but perform random actions for 2 seconds before considering the reset finished. \n",
    "This will improve state-space coverage even more, because we now also allow for non-zero angular velocity resets. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
