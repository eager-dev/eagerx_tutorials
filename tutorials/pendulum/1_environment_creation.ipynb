{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65b4e05a",
   "metadata": {},
   "source": [
    "# Tutorial 1: Environment Creation and Training\n",
    "\n",
    "In this tutorial, we will show a simple example of how to create a gym environment using [EAGERx](https://eagerx.readthedocs.io/en/master/).\n",
    "Also, we will use this environment to train a policy using [Stable Baselines 3](https://stable-baselines3.readthedocs.io/en/master/).\n",
    "\n",
    "The following will be covered:\n",
    "- Creating a [Graph](https://eagerx.readthedocs.io/en/master/guide/api_reference/graph/graph.html) with an [Object](https://eagerx.readthedocs.io/en/master/guide/api_reference/object/index.html)\n",
    "- How to use this [Graph](https://eagerx.readthedocs.io/en/master/guide/api_reference/graph/graph.html) and a [Engine](https://eagerx.readthedocs.io/en/master/guide/api_reference/engine/index.html) to create an [Eagerx Environment](https://eagerx.readthedocs.io/en/master/guide/api_reference/env/index.html)\n",
    "- How to train a policy with the [EAGERx Environment](https://eagerx.readthedocs.io/en/master/guide/api_reference/env/index.html)\n",
    "\n",
    "In the remainder of this tutorial we will go more into detail on these concepts.\n",
    "\n",
    "\n",
    "## Pendulum Swing-up\n",
    "\n",
    "We will create an environment for solving the classic control problem of swinging up an underactuated pendulum, very similar to the [Pendulum-v1 environment](https://www.gymlibrary.ml/environments/classic_control/pendulum/).\n",
    "Our goal is to swing up this pendulum to the upright position and keep it there, while minimizing the velocity of the pendulum and the input voltage.\n",
    "\n",
    "Since the dynamics of a pendulum actuated by a DC motor are well known, we can simulate the pendulum by integrating the corresponding ordinary differential equations (ODEs):\n",
    "\n",
    "\n",
    "$\\mathbf{x} = \\begin{bmatrix} \\theta \\\\ \\dot{\\theta} \\end{bmatrix} \\\\ \\dot{\\mathbf{x}} = \\begin{bmatrix} \\dot{\\theta} \\\\ \\frac{1}{J}(\\frac{K}{R}u - mgl \\sin{\\theta} - b \\dot{\\theta} - \\frac{K^2}{R}\\dot{\\theta})\\end{bmatrix}$\n",
    "\n",
    "with $\\theta$ the angle w.r.t. upright position, $\\dot{\\theta}$ the angular velocity, $u$ the input voltage, $J$ the inertia, $m$ the mass, $g$ the gravitational constant, $l$ the length of the pendulum, $b$ the motor viscous friction constant, $K$ the motor constant and $R$ the electric resistance.\n",
    "\n",
    "<img src=\"./figures/pendulum.GIF\" width=\"480\" />\n",
    "\n",
    "\n",
    "## Activate GPU (Colab only)\n",
    "\n",
    "When in Colab, you'll need to enable GPUs for the notebook:\n",
    "\n",
    "- Navigate to Editâ†’Notebook Settings\n",
    "- select GPU from the Hardware Accelerator drop-down\n",
    "\n",
    "\n",
    "## Notebook Setup\n",
    "\n",
    "In order to be able to run the code, we need to install the *eagerx_tutorials* package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7485878-73c8-43fc-8b9a-a8fc9d8e1775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not running on CoLab.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import eagerx_tutorials\n",
    "except ImportError:\n",
    "    !{\"echo 'Installing eagerx-tutorials with pip.' && pip install eagerx-tutorials >> /tmp/eagerx_install.txt 2>&1\"}\n",
    "\n",
    "# Setup interactive notebook\n",
    "# Required in interactive notebooks only.\n",
    "from eagerx_tutorials import helper\n",
    "helper.setup_notebook()\n",
    "\n",
    "# Import eagerx\n",
    "import eagerx\n",
    "eagerx.set_log_level(eagerx.WARN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701e0a93",
   "metadata": {},
   "source": [
    "## Let's get started\n",
    "\n",
    "An `Object` is an entity that has inputs (sensors), outputs (actuators) and states (that can be reset at the beginning of an episode).\n",
    "\n",
    "We are going to create one object (the pendulum). For this first tutorial, we don't want to go into details too much and start with existing objects.\n",
    "Note that we import the pendulum.\n",
    "While this might look like an unused import, it is not.\n",
    "During the import, the pendulum object is registered and we can therefore make it based on its ID, i.e. *Pendulum*.\n",
    "\n",
    "Before making the object, we will first obtain some info on the *Pendulum*, such that we know with what arguments we should make it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eeaac748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   entity_type: `Pendulum`\n",
      "   module: `eagerx_tutorials.pendulum.objects`\n",
      "   file: `/home/bas/eagerx_dev/eagerx_tutorials/eagerx_tutorials/pendulum/objects.py`\n",
      "\n",
      "Supported engines:\n",
      " - eagerx_ode.engine/OdeEngine\n",
      "\n",
      "Make this spec with:\n",
      "   spec = Pendulum.make(name: str, actuators: List[str] = None, sensors: List[str] = None, states: List[str] = None, rate: float = 30.0, render_shape: List[int] = None, render_fn: str = None)\n",
      "\n",
      "class Pendulum:\n",
      "   make(name: str, actuators: List[str] = None, sensors: List[str] = None, states: List[str] = None, rate: float = 30.0, render_shape: List[int] = None, render_fn: str = None):\n",
      "      sensors:\n",
      "       - theta: Space(-999.0, 999.0, (), float32)\n",
      "       - dtheta: Space(-999.0, 999.0, (), float32)\n",
      "       - image: Space(uint8)\n",
      "       - u_applied: Space([-2.], [2.], (1,), float32)\n",
      "      actuators:\n",
      "       - u: Space([-2.], [2.], (1,), float32)\n",
      "      engine_states:\n",
      "       - model_state: Space([-3.14 -9.  ], [3.14 9.  ], (2,), float32)\n",
      "       - model_parameters: Space(float32)\n",
      "       - mass: Space(0.009999999776482582, 0.07000000029802322, (), float32)\n",
      "       - length: Space(0.03999999910593033, 0.20000000298023224, (), float32)\n",
      "       - max_speed: Space(22.0, 22.0, (), float32)\n",
      "      docs:\n",
      "         Make the specification of the Pendulum.\n",
      "\n",
      "                 Sensors\n",
      "                 theta: angle of the pendulum wrt upward position\n",
      "                 dtheta: angular velocity of the pendulum\n",
      "                 image: render of pendulum system\n",
      "                 u_applied: Applied DC motor voltage\n",
      "\n",
      "                 Actuators\n",
      "                 u: DC motor voltage\n",
      "\n",
      "                 States\n",
      "                 model_state: allows resetting the angle and angular velocity\n",
      "                 model_parameters: allows resetting all ODE parameters [J, m, l, b, K, R, c, d].\n",
      "                 mass: allows resetting the mass of the Gym pendulum m\n",
      "                 length: allows resetting the length of the Gym pendulum l\n",
      "                 max_speed: allows resetting the max speed of the Gym pendulum\n",
      "\n",
      "                 Config\n",
      "                 render_shape: shape of render window [height, width]\n",
      "        \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from eagerx_tutorials.pendulum.objects import Pendulum\n",
    "\n",
    "Pendulum.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94acafd2-ea83-4bfe-aeb1-76fa251fec47",
   "metadata": {},
   "source": [
    "We see that the `eagerx.Object.info(\"Pendulum\")` provides us information on the *Pendulum* object.\n",
    "It has four sensors (*theta*, *dtheta*, *image*, *u_applied*), one actuator (*u*) and two states (*model_state*, *model_parameters*).\n",
    "Here *theta*, *dtheta* and *u* correspond to $\\theta$, $\\dot{\\theta}$ and $u$, respectively.\n",
    "For now, we are only interested in how to make this object, other information will be covered in later tutorials.\n",
    "We can make the *Pendulum* object with the `eagerx.Object.make` method with the required arguments *entity_id* and (a unique) *name*.\n",
    "Furthermore, we will specify which actuators, sensors and states we will use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da5a5a0e-6502-4ac1-9b27-c3e207a8c47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make pendulum\n",
    "pendulum = Pendulum.make(\"pendulum\", actuators=[\"u\"], sensors=[\"theta\", \"dtheta\", \"image\"], states=[\"model_state\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2f0c2d",
   "metadata": {},
   "source": [
    "Next, we create a [Graph](https://eagerx.readthedocs.io/en/master/guide/api_reference/graph/graph.html) and add the pendulum to it.\n",
    "\n",
    "The graph describes the interconnection of nodes and objects.\n",
    "In this way, the creation of an environment becomes modular.\n",
    "This allows users to create an implementation for nodes and objects once, and easily create new environments by reusing these implementations.\n",
    "Also, this allows to construct complex environments using nodes and objects as basic building blocks.\n",
    "\n",
    "After adding the pendulum to the graph, we will connect the actuator *u* to a new action called *voltage*.\n",
    "We will connect the sensors *theta* and *dtheta* to the observations *angle* and *angular_velocity*, respectively.\n",
    "In this way, the agent will be able to send actions to control $u$ of the pendulum and observe $\\theta$ and $\\dot{\\theta}$.\n",
    "\n",
    "Finally, we will also render the *image* sensor in order to visualize the pendulum.\n",
    "More detailed information on rendering is covered in another tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2686fa8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define rate (depends on rate of ode)\n",
    "rate = 30.0\n",
    "\n",
    "# Initialize empty graph\n",
    "graph = eagerx.Graph.create()\n",
    "\n",
    "# Add pendulum to the graph\n",
    "graph.add(pendulum)\n",
    "\n",
    "# Connect the pendulum to an action and observation\n",
    "graph.connect(action=\"voltage\", target=pendulum.actuators.u)\n",
    "graph.connect(source=pendulum.sensors.theta, observation=\"angle\")\n",
    "graph.connect(source=pendulum.sensors.dtheta, observation=\"angular_velocity\")\n",
    "\n",
    "# Render image\n",
    "graph.render(source=pendulum.sensors.image, rate=rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f0b265",
   "metadata": {},
   "source": [
    "It is also possible to inspect the graph using the eagerx-gui package.\n",
    "It can be installed as follows:\n",
    "```bash\n",
    "pip3 install eagerx-gui\n",
    "```\n",
    "Jupyter notebooks have limited support for interactive applications, so we cannot open the GUI here.\n",
    "But if we were to run\n",
    "```python\n",
    "graph.gui()\n",
    "```\n",
    "The ouput would be as follows:\n",
    "\n",
    "<img src=\"./figures/tutorial_1_gui.svg\" width=720>\n",
    "\n",
    "Here we see that the actions of the agent are outputs of *env/actions* and that the observations of the agent are inputs of *env/observations*.\n",
    "Also, we could render output by connecting to *env/render*, which will be covered in another tutorial.\n",
    "Note that *env/actions*, *env/observations* and *env/render* represent connections of the `Graph` to the environment.\n",
    "They are split up in the GUI as nodes for visualization purposes.\n",
    "\n",
    "Next, we will create the [Environment](https://eagerx.readthedocs.io/en/master/guide/api_reference/env/index.html).\n",
    "Environment creation in EAGERx follows the same API as Gym, i.e. we have to define a [step()](https://eagerx.readthedocs.io/en/master/guide/api_reference/env/index.html#eagerx.core.env.BaseEnv.step) and [reset()](https://eagerx.readthedocs.io/en/master/guide/api_reference/env/index.html#eagerx.core.env.BaseEnv.reset) method.\n",
    "\n",
    "Just like in normal Gym environments, we will create a step function in which we will calculate the reward at each time step and check for termination conditions.\n",
    "Our goal is to stabilize the pendulum in upright position, while minimizing the input voltage that is applied.\n",
    "Therefore we choose a reward function that is a weighted sum of $\\theta^2$, $\\dot{\\theta^2}$ and $u^2$.\n",
    "\n",
    "Note that we can obtain the values of the actions and observations using the keys *voltage*, *angle* and *angular_velocity*, which correspond to the names of the actions and observations above in the screenshot of the GUI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e829569-62a0-40a6-ab0d-261daa505cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class PendulumEnv(eagerx.BaseEnv):\n",
    "    def __init__(self, name: str, rate: float, graph: eagerx.Graph, engine: eagerx.specs.EngineSpec, backend: eagerx.specs.BackendSpec):\n",
    "        \"\"\"Initializes an environment with EAGERx dynamics.\n",
    "\n",
    "        :param name: The name of the environment. Everything related to this environment\n",
    "                     (parameters, topics, nodes, etc...) will be registered under namespace: \"/[name]\".\n",
    "        :param rate: The rate (Hz) at which the environment will run.\n",
    "        :param graph: The graph consisting of nodes and objects that describe the environment's dynamics.\n",
    "        :param engine: The physics engine that will govern the environment's dynamics.\n",
    "        :param backend: The backend that manages all communication and the parameter server.\n",
    "        \"\"\"\n",
    "        self.eval = eval\n",
    "        \n",
    "        # Maximum episode length\n",
    "        self.max_steps = 100\n",
    "        \n",
    "        # Step counter\n",
    "        self.steps = None\n",
    "        super().__init__(name, rate, graph, engine, backend, force_start=True)\n",
    "    \n",
    "    def step(self, action: Dict):\n",
    "        \"\"\"A method that runs one timestep of the environment's dynamics.\n",
    "\n",
    "        :params action: A dictionary of actions provided by the agent.\n",
    "        :returns: A tuple (observation, reward, done, info).\n",
    "\n",
    "            - observation: Dictionary of observations of the current timestep.\n",
    "\n",
    "            - reward: amount of reward returned after previous action\n",
    "\n",
    "            - done: whether the episode has ended, in which case further step() calls will return undefined results\n",
    "\n",
    "            - info: contains auxiliary diagnostic information (helpful for debugging, and sometimes learning)\n",
    "        \"\"\"\n",
    "        # Take step\n",
    "        observation = self._step(action)\n",
    "        self.steps += 1\n",
    "        \n",
    "        # Get angle and angular velocity\n",
    "        # Take first element because of window size (covered in other tutorial)\n",
    "        th = observation[\"angle\"][0] \n",
    "        thdot = observation[\"angular_velocity\"][0]\n",
    "\n",
    "        # Convert from numpy array to float\n",
    "        u = float(action[\"voltage\"])\n",
    "\n",
    "        # Normalize angle so it lies in [-pi, pi]\n",
    "        th -= 2 * np.pi * np.floor((th + np.pi) / (2 * np.pi))\n",
    "\n",
    "        # Calculate cost\n",
    "        # Penalize angle error, angular velocity and input voltage\n",
    "        cost = th**2 + 0.1 * thdot**2 + 0.001 * u**2  \n",
    "\n",
    "        # Determine when is the episode over\n",
    "        # currently just a timeout after 100 steps\n",
    "        done = self.steps > self.max_steps\n",
    "\n",
    "        # Set info, tell the algorithm the termination was due to a timeout\n",
    "        # (the episode was truncated)\n",
    "        info = {\"TimeLimit.truncated\": self.steps > self.max_steps}\n",
    "        \n",
    "        return observation, -cost, done, info\n",
    "    \n",
    "    def reset(self) -> Dict:\n",
    "        \"\"\"Resets the environment to an initial state and returns an initial observation.\n",
    "\n",
    "        :returns: The initial observation.\n",
    "        \"\"\"\n",
    "        # Determine reset states\n",
    "        states = self.state_space.sample()\n",
    "            \n",
    "        # Perform reset\n",
    "        observation = self._reset(states)\n",
    "\n",
    "        # Reset step counter\n",
    "        self.steps = 0\n",
    "        return observation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8410ce6",
   "metadata": {},
   "source": [
    "Next, we will make a specification with which we can initialize an [Engine](https://eagerx.readthedocs.io/en/master/guide/api_reference/engine/index.html).\n",
    "Since objects can have implementions for multiple physics engines and real systems, we need to initialize the appropriate engine.\n",
    "In our case, we will use the [OdeEngine](https://github.com/eager-dev/eagerx_ode), which allows to simulate systems based on ordinary differential equations (ODEs).\n",
    "In more advanced tutorials we will go more into detail on the engine and how you can create your own engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "badb2076",
   "metadata": {},
   "outputs": [],
   "source": [
    "from eagerx_ode.engine import OdeEngine\n",
    "\n",
    "# Make the engine specification\n",
    "engine = OdeEngine.make(rate=rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c48b43",
   "metadata": {},
   "source": [
    "Then, we will make a specification with which we can initialize an [Backend](https://eagerx.readthedocs.io/en/master/guide/api_reference/backend/index.html). The backend takes care of all communication between nodes and manages the parameter server. Depending on the backend, the support for [distributed computation](https://en.wikipedia.org/wiki/Distributed_computing), [Google Colab](https://colab.research.google.com/?utm_source=scs-index), and [multi-processing](https://en.wikipedia.org/wiki/Multiprocessing) may differ. There are already two backends available, but users can also define their own:\n",
    "\n",
    "|  | Google Colab | Distributed | Multi-processing |\n",
    "| ---- | --- | --- | --- |\n",
    "| eagerx.backends.ros1.Ros1 | <center>&cross;</center> | <center>&#10004;</center> | <center>&#10004;</center> |\n",
    "| eagerx.backends.single_process.SingleProcess | <center>&#10004;</center> | <center>&cross;</center> | <center>&cross;</center> |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce0a8f5a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from eagerx.backends.single_process import SingleProcess\n",
    "\n",
    "# Make the backend specification\n",
    "backend = SingleProcess.make()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ae7093",
   "metadata": {},
   "source": [
    "Having created a graph, an engine and a step function, we can now construct the EAGERx environment.\n",
    "We can use it like any other Gym environment.\n",
    "Here we will now train a policy to swing up the pendulum using the Soft Actor Critic (SAC) reinforcement learning algorithm implementation from [Stable Baselines 3](https://stable-baselines3.readthedocs.io/en/master/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19aaa2b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m[WARN]: Backend 'SINGLE_PROCESS' does not support multiprocessing, so all nodes are launched in the ENVIRONMENT process.\u001b[0m\n",
      "action_space:  Dict(voltage:Space([-2.], [2.], (1,), float32))\n",
      "observation_space:  Dict(angle:Box([-999.], [999.], (1,), float32), angular_velocity:Box([-999.], [999.], (1,), float32))\n",
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 101       |\n",
      "|    ep_rew_mean     | -1.05e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 4         |\n",
      "|    fps             | 81        |\n",
      "|    time_elapsed    | 4         |\n",
      "|    total_timesteps | 404       |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 18.8      |\n",
      "|    critic_loss     | 15        |\n",
      "|    ent_coef        | 0.915     |\n",
      "|    ent_coef_loss   | -0.132    |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 303       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 101       |\n",
      "|    ep_rew_mean     | -1.01e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 8         |\n",
      "|    fps             | 75        |\n",
      "|    time_elapsed    | 10        |\n",
      "|    total_timesteps | 808       |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 34.6      |\n",
      "|    critic_loss     | 25.7      |\n",
      "|    ent_coef        | 0.826     |\n",
      "|    ent_coef_loss   | -0.209    |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 707       |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 101      |\n",
      "|    ep_rew_mean     | -1e+03   |\n",
      "| time/              |          |\n",
      "|    episodes        | 12       |\n",
      "|    fps             | 71       |\n",
      "|    time_elapsed    | 17       |\n",
      "|    total_timesteps | 1212     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 49.1     |\n",
      "|    critic_loss     | 24.9     |\n",
      "|    ent_coef        | 0.742    |\n",
      "|    ent_coef_loss   | -0.357   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 1111     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 101      |\n",
      "|    ep_rew_mean     | -998     |\n",
      "| time/              |          |\n",
      "|    episodes        | 16       |\n",
      "|    fps             | 70       |\n",
      "|    time_elapsed    | 22       |\n",
      "|    total_timesteps | 1616     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 65.9     |\n",
      "|    critic_loss     | 16.8     |\n",
      "|    ent_coef        | 0.658    |\n",
      "|    ent_coef_loss   | -0.543   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 1515     |\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "import stable_baselines3 as sb3\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from eagerx.wrappers import Flatten\n",
    "from gym.wrappers.rescale_action import RescaleAction\n",
    "\n",
    "# Initialize Environment\n",
    "env = PendulumEnv(name=\"PendulumEnv\", rate=rate, graph=graph, engine=engine, backend=backend)\n",
    "\n",
    "# Print action & observation space\n",
    "print(\"action_space: \", env.action_space)\n",
    "print(\"observation_space: \", env.observation_space)\n",
    "\n",
    "# Stable Baselines3 expects flattened actions & observations\n",
    "# Convert observation and action space from Dict() to Box(), normalize actions\n",
    "env = Flatten(env)\n",
    "env = RescaleAction(env, min_action=-1.0, max_action=1.0)\n",
    "\n",
    "# Check that env follows Gym API and returns expected shapes\n",
    "check_env(env)\n",
    "\n",
    "# Toggle render\n",
    "env.render(\"human\")\n",
    "\n",
    "# Initialize learner\n",
    "model = sb3.SAC(\"MlpPolicy\", env, verbose=1)\n",
    "\n",
    "# Train for 1 minute (sim time)\n",
    "model.learn(total_timesteps=int(60 * rate))\n",
    "\n",
    "env.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f005986f-d256-4b5c-8986-8b9dbc32f02b",
   "metadata": {},
   "source": [
    "### Note\n",
    "This environments runs without errors, but the agent will not yet learn to swing up the pendulum... In the next tutorials you will find out why (*hint: it has to do with the definition of the spaces*), and how you can use eagerx to easily redefine this environment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4723c6ee-48e1-4223-8eb5-1c883434ea4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
